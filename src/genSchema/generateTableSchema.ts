import { promises as fs } from 'node:fs'
import { resolve } from 'node:path'

import { mkdirp } from 'mkdirp'
import { rimraf } from 'rimraf'

import { getTableInfo } from '../database/getTableInfo.js'
import { toCamelCase } from '../helper/toCamelCase.js'
import { toUpperCamelCase } from '../helper/toUpperCamelCase.js'
import { ensureRecordSchema } from './ensureRecordSchema.js'
import { mergeNested } from './mergeNested.js'

export const generateSchemaForTable = async (name: string, tableInfo: string) => {
	const isSchemaFull = !!tableInfo?.toUpperCase().includes('SCHEMAFULL')

	const { fields } = await getTableInfo(name)

	let inputFields = mergeNested(fields, true, name)
	let outputFields = mergeNested(fields, false, name)

	if (!isSchemaFull) {
		inputFields += '.passthrough()'
		outputFields += '.passthrough()'
	}

	return {
		inputFields,
		outputFields,
	}
}

const createIndexFile = async (directory: string, files: string[]): Promise<void> => {
	const indexContent = files
		.map(file => {
			const baseName = file.replace(/\.ts$/, '')
			return `export * from './${baseName}.js';`
		})
		.join('\n')

	await fs.writeFile(resolve(directory, 'index.ts'), indexContent)
}

export const generateTableSchema = async (outFolder: string, tableInfo: Record<string, string>): Promise<void> => {
	try {
		await mkdirp(outFolder)

		const genSchemaFolder = resolve(outFolder, '_generated')

		console.log('Generating schema in', genSchemaFolder)

		await ensureRecordSchema(genSchemaFolder)

		const generatedFiles: string[] = []

		for (const name in tableInfo) {
			const { inputFields, outputFields } = await generateSchemaForTable(name, tableInfo[name]!)

			const tableName = toCamelCase(name)
			const tableSchemaFolder = resolve(genSchemaFolder, tableName)
			console.log(`üëâ [${tableName}]: ${tableSchemaFolder}`)
			await rimraf(tableSchemaFolder)
			await mkdirp(tableSchemaFolder)

			const genSchemaFileName = resolve(tableSchemaFolder, `${toCamelCase(tableName)}SchemaGen.ts`)

			const injectRecordSchema = inputFields.includes('recordId(') || outputFields.includes('recordId(')

			const schemaContent = `// ====================
// DO NOT EDIT THIS FILE!
// This file is autogenerated and will be overwritten during generation!
// ====================

import { z } from "zod";
${injectRecordSchema ? 'import { recordId } from "../recordSchema.js"' : ''}

// the create schema for table ${name}
export ${inputFields};

// the select schema for table ${name}
export ${outputFields};
`

			await fs.writeFile(genSchemaFileName, schemaContent)
			console.log(` ‚úÖ [${tableName}]: ${tableName}SchemaGen.ts`)

			generatedFiles.push(`${tableName}/${toCamelCase(tableName)}SchemaGen.ts`)

			const schemaFolder = resolve(outFolder, 'schema', tableName)
			await mkdirp(schemaFolder)

			const schemaFileName = `${toCamelCase(tableName)}Schema.ts`
			const fullSchemaFileName = resolve(schemaFolder, schemaFileName)

			if (!(await fs.stat(fullSchemaFileName).catch(() => false))) {
				const schemaFileContent = `/* Place your custom changes here */

import { z } from "zod";

import { ${tableName}InputSchemaGen, ${tableName}OutputSchemaGen } from "../../_generated/index.js";
import { recordId } from "../../_generated/recordSchema.js";

// payload schema for creating a new ${name} entity
export const ${tableName}CreateSchema = ${tableName}InputSchemaGen.merge(z.object({
  id: recordId("${tableName}").optional()
  // add your custom fields here, which are not part of SurrealDB table schema
  // they are not overwritten by the next run
      }))

// payload schema for fetching a ${name} entity
export const ${tableName}Schema = ${tableName}OutputSchemaGen.merge(z.object({
  id: recordId("${tableName}"),
  // add your custom fields here, which are not part of SurrealDB table schema
  // they are not overwritten by the next run
      }))
`
				await fs.writeFile(fullSchemaFileName, schemaFileContent)
				console.log(` ‚úÖ [${tableName}]: ${schemaFileName}`)
			} else {
				console.log(` ‚ùé [${tableName}]: ${schemaFileName} already exists`)
			}

			const typeFileName = `${toCamelCase(tableName)}Types.ts`
			const fullTypeFileName = resolve(schemaFolder, typeFileName)

			if (!(await fs.stat(fullTypeFileName).catch(() => false))) {
				const typeFileContent = `/* Place your custom changes here */

import { z } from "zod";
import { type RecordId} from "surrealdb.js";

import { ${tableName}CreateSchema, ${tableName}Schema } from "./${tableName}Schema.js";

// the create type for table ${name}
export type ${toUpperCamelCase(tableName)}Create = z.input<typeof ${tableName}CreateSchema>

// the select type for table ${name}
export type ${toUpperCamelCase(tableName)} = z.output<typeof ${tableName}Schema> & {id: RecordId<string>}
      `
				await fs.writeFile(fullTypeFileName, typeFileContent)
				console.log(` ‚úÖ [${tableName}]: ${typeFileName}`)
			} else {
				console.log(` ‚ùé [${tableName}]: ${typeFileName} already exists`)
			}

			const indexFileName = resolve(schemaFolder, 'index.ts')
			if (!(await fs.stat(indexFileName).catch(() => false))) {
				await createIndexFile(schemaFolder, [schemaFileName, typeFileName])
				console.log(` ‚úÖ [${tableName}]: index.ts`)
			} else {
				console.log(` ‚ùé [${tableName}]: index.ts already exists`)
			}
		}

		const mainSchemaFolder = resolve(outFolder, 'schema')
		const mainIndexFileName = resolve(mainSchemaFolder, 'index.ts')
		const mainIndexContent = Object.keys(tableInfo)
			.map(name => `export * from './${toCamelCase(name)}/index.js';`)
			.join('\n')
		await fs.writeFile(mainIndexFileName, mainIndexContent)
		console.log(' ‚úÖ Created/Updated main schema index.ts')

		const genIndexFileName = resolve(genSchemaFolder, 'index.ts')
		if (!(await fs.stat(genIndexFileName).catch(() => false))) {
			await createIndexFile(genSchemaFolder, generatedFiles)
			console.log(' ‚úÖ Created _generated/index.ts')
		} else {
			console.log(' ‚ùé _generated/index.ts already exists')
		}

	} catch (error) {
		console.error('An error occurred during schema generation:', error)
		throw error
	}
}